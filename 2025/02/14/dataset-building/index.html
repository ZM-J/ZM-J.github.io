<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例 | 春勃</title><meta name="author" content="ZM-J"><meta name="copyright" content="ZM-J"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="众所周知，keras 数据集的实现主要依赖于两派：  一派为 keras 提供的数据集相关接口，其中包括已经封装好的几个 toy dataset，还有一些 预处理函数 虽然预处理函数被标成 deprecated，但是貌似函数功能没变，只是被挪了个地方，应该都是进到 keras.utils 里面了   另一派为显式实现 tf.data pipeline  官方推荐用 tf.data 去构建 Tens">
<meta property="og:type" content="article">
<meta property="og:title" content="如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例">
<meta property="og:url" content="https://zm-j.github.io/2025/02/14/dataset-building/index.html">
<meta property="og:site_name" content="春勃">
<meta property="og:description" content="众所周知，keras 数据集的实现主要依赖于两派：  一派为 keras 提供的数据集相关接口，其中包括已经封装好的几个 toy dataset，还有一些 预处理函数 虽然预处理函数被标成 deprecated，但是貌似函数功能没变，只是被挪了个地方，应该都是进到 keras.utils 里面了   另一派为显式实现 tf.data pipeline  官方推荐用 tf.data 去构建 Tens">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zm-j.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2025-02-14T08:50:09.000Z">
<meta property="article:modified_time" content="2025-02-14T08:52:23.873Z">
<meta property="article:author" content="ZM-J">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="keras">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zm-j.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zm-j.github.io/2025/02/14/dataset-building/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-02-14 16:52:23'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">46</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="春勃"><span class="site-name">春勃</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-02-14T08:50:09.000Z" title="Created 2025-02-14 16:50:09">2025-02-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-02-14T08:52:23.873Z" title="Updated 2025-02-14 16:52:23">2025-02-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>众所周知，keras 数据集的实现主要依赖于两派：</p>
<ul>
<li>一派为 <code>keras</code> 提供的数据集相关接口，其中包括已经封装好的几个 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets">toy dataset</a>，还有一些 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing">预处理函数</a><ul>
<li>虽然预处理函数被标成 deprecated，但是貌似函数功能没变，只是被挪了个地方，应该都是进到 <code>keras.utils</code> 里面了</li>
</ul>
</li>
<li>另一派为显式实现 <code>tf.data</code> pipeline</li>
</ul>
<p>官方推荐用 <code>tf.data</code> 去构建 TensorFlow 输入流水线，更多参考 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/guide/data">官方教程</a></p>
<p>先给一个太长不看的结论：</p>
<ul>
<li>如果图省事+不需要定制需求的话就用 keras 自带的接口就好</li>
<li>实在想折腾的话建议优先关注 mini-batch 的 <code>batch_size</code> 设置</li>
<li>然后注意向量化运算的利用</li>
</ul>
<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>工地上涉及到的数据集是比较客制化的时序数据集，可以描述为下面的场景</p>
<ul>
<li>输入 <code>X</code> 和 <code>y</code>，以及下标序列 <code>index</code></li>
<li><code>X</code> 的 shape 为 <code>(num_samples, num_features)</code>, <code>y</code> 的 shape 为 <code>num_samples</code></li>
<li>设置时间序列长度为 <code>sequence_length</code></li>
<li>对于每个 <code>index</code> 中的元素 <code>i</code>，抽出 <code>(X[i-sequence_length+1:i+1], y[i])</code> 作为一笔数据</li>
<li>收集 <code>batch_size</code> 笔这样的数据作为一个 batch 的数据，送到模型里面进行训练和推理</li>
</ul>
<p>特别地，当 <code>index</code> 取为全集的时候（每个能抽的数据都利用去训练，也即 <code>index=[sequence_length-1, l, ..., num_samples]</code>），该功能可以用 <code>keras.utils.timeseries_dataset_from_array</code> 来实现，参考：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;VISIBLE_CUDA_DEVICES&#x27;</span>] = <span class="string">&#x27;-1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> timeseries_dataset_from_array </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_samples = <span class="number">10000</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_samples * num_features).reshape(num_samples, num_features)</span><br><span class="line">y = np.arange(num_samples)</span><br><span class="line"></span><br><span class="line">dataset = timeseries_dataset_from_array(X,</span><br><span class="line">                                        y,</span><br><span class="line">                                        sequence_length,</span><br><span class="line">                                        batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">Xi, yi = dataset.take(<span class="number">1</span>).as_numpy_iterator().<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>观察上述输出，发现要使用该 API，还需在 <code>y</code> 的前面加上 <code>l-1</code> 个 padding 才能匹配上我们上面描述的那个需求</p>
<p>但是由于我们加了对数据集上的采样，不能直接调用这玩意儿</p>
<h2 id="一开始的做法"><a href="#一开始的做法" class="headerlink" title="一开始的做法"></a>一开始的做法</h2><h3 id="简易实现"><a href="#简易实现" class="headerlink" title="简易实现"></a>简易实现</h3><p>首先想到的（能被搜出来的）就是先实现一个吐出单笔数据的数据集，然后利用 <code>tf.data.Dataset.from_generator</code> 将一个 generator 封装为 <code>tf.data.Dataset</code>，然后在这基础上再去加 <code>batch</code>，<code>prefetch</code>，<code>cache</code> 等操作构造 mini-batch</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;VISIBLE_CUDA_DEVICES&#x27;</span>] = <span class="string">&#x27;-1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_samples = <span class="number">10000</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_samples * num_features).reshape(num_samples, num_features)</span><br><span class="line">y = np.arange(num_samples)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_sample_generator</span>(<span class="params">X: np.ndarray, y: np.ndarray, index: np.ndarray</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample_generator</span>():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">            <span class="keyword">yield</span> X[i-sequence_length+<span class="number">1</span>:i+<span class="number">1</span>], y[i]</span><br><span class="line">    <span class="keyword">return</span> sample_generator</span><br><span class="line"></span><br><span class="line">output_signature = (</span><br><span class="line">    tf.TensorSpec(shape=(sequence_length, num_features), dtype=tf.float32),</span><br><span class="line">    tf.TensorSpec(shape=(), dtype=tf.float32)</span><br><span class="line">)</span><br><span class="line">g = get_sample_generator(X, y, np.arange(sequence_length-<span class="number">1</span>, <span class="built_in">len</span>(X)))</span><br><span class="line">dataset = tf.data.Dataset.from_generator(g, output_signature=output_signature)</span><br><span class="line">dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)</span><br><span class="line"></span><br><span class="line">Xi, yi = dataset.take(<span class="number">1</span>).as_numpy_iterator().<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>一开始就是走这个简易实现，不过马上发现问题：训练第 1 个 epoch 用时过久，似乎能通过加 cache 来“绕过”后续 epoch 训练的问题。猜测瓶颈出在数据集吐数据上。</p>
<h3 id="性能分析方法"><a href="#性能分析方法" class="headerlink" title="性能分析方法"></a>性能分析方法</h3><p>一个手段是弄一个简单的模型去跑模型训练，利用 tensorflow profiler 查看前面 step 的 profile 结果，可以清晰地看到看到当 <code>batch_size=10000</code> 时，绝大多数时间都耗在了输入生成的阶段</p>
<p>还有一个手段是利用 line_profiler 分析，去尝试单步迭代数据集，看看主要耗时都在哪一行，绝对时长多少，并且针对热点去调整实现</p>
<p>譬如上面简易实现的 profiler 结果，如下：</p>
<p><img src="simple_profiler.png" alt="简易实现"></p>
<h3 id="暴力实现"><a href="#暴力实现" class="headerlink" title="暴力实现"></a>暴力实现</h3><p>简易实现取数据慢的核心原因是因为抽样和窗口化操作需要每次都老老实实去取才行。为了绕过这个在线生成的过程，一个很自然的方法就是先预先（离线）生成形状为 <code>（num_index, sequence_length, num_features)</code> 的全量数据，然后利用 <code>tf.data.Dataset.from_tensor_slices</code> 来生成迭代数据集。这样做的好处就是 <code>__getitem__</code> 或者 <code>__iter__</code> 的时候（理论上）不存在在线计算的瓶颈；而且离线生成的时候也可以用到一些向量化操作的 trick 来批量化取下标</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;VISIBLE_CUDA_DEVICES&#x27;</span>] = <span class="string">&#x27;-1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_samples = <span class="number">10000</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_samples * num_features).reshape(num_samples, num_features)</span><br><span class="line">y = np.arange(num_samples)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_full_dataset</span>(<span class="params">X: np.ndarray, y: np.ndarray, index: np.ndarray</span>):</span><br><span class="line">    num_index = <span class="built_in">len</span>(index)</span><br><span class="line">    X_full = np.zeros((num_index, sequence_length, num_features), dtype=np.float32)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(sequence_length):</span><br><span class="line">        current_index = index + i - sequence_length + <span class="number">1</span></span><br><span class="line">        X_full[:, i, :] = X[current_index, :]</span><br><span class="line">    y_full = y[index]</span><br><span class="line">    <span class="keyword">return</span> X_full, y_full</span><br><span class="line"></span><br><span class="line">index = np.arange(sequence_length-<span class="number">1</span>, <span class="built_in">len</span>(X))</span><br><span class="line">X_full, y_full = get_full_dataset(X, y, index)</span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((X_full, y_full))</span><br><span class="line">dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)</span><br><span class="line"></span><br><span class="line">Xi, yi = dataset.take(<span class="number">1</span>).as_numpy_iterator().<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>但是这有一个问题：工地上的 dataframe 往往会比较大，一个 dataframe 勉强能被内存装下，但是 <code>sequence_length</code> 个 dataframe 是装不下的。如果用到虚拟内存的话，那么整个过程又会变得奇慢无比。所以这个实现对于大数据集来说是不现实的。</p>
<h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><h3 id="魔改-keras-utils-timeseries-dataset-from-array"><a href="#魔改-keras-utils-timeseries-dataset-from-array" class="headerlink" title="魔改 keras.utils.timeseries_dataset_from_array"></a>魔改 <code>keras.utils.timeseries_dataset_from_array</code></h3><p>首先我们假设 <code>keras.utils.timeseries_dataset_from_array</code> 的实现是要更加好的，然后进到 <a target="_blank" rel="noopener" href="https://github.com/keras-team/tf-keras/blob/master/tf_keras/utils/timeseries_dataset.py">具体实现</a> 里面，把</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start_positions = np.arange(<span class="number">0</span>, num_seqs, sequence_stride, dtype=index_dtype)</span><br></pre></td></tr></table></figure>
<p>替换成我们定制的下标就好了</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;VISIBLE_CUDA_DEVICES&#x27;</span>] = <span class="string">&#x27;-1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sequences_from_indices</span>(<span class="params">array, indices_ds: tf.data.Dataset</span>):</span><br><span class="line">    dataset = tf.data.Dataset.from_tensors(array).repeat()</span><br><span class="line">    dataset = tf.data.Dataset.<span class="built_in">zip</span>((dataset, indices_ds)).<span class="built_in">map</span>(</span><br><span class="line">        <span class="keyword">lambda</span> steps, inds: tf.gather(steps, inds),</span><br><span class="line">        num_parallel_calls=tf.data.AUTOTUNE,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_sequence_dataset</span>(<span class="params">X: np.ndarray,</span></span><br><span class="line"><span class="params">                         Y: np.ndarray,</span></span><br><span class="line"><span class="params">                         index: np.ndarray,</span></span><br><span class="line"><span class="params">                         sequence_length: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                         batch_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                         shuffle: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(index) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> tf.data.Dataset.<span class="built_in">range</span>(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Always generate the same content</span></span><br><span class="line">    positions_ds = tf.data.Dataset.from_tensors(index).repeat()</span><br><span class="line">    <span class="comment"># For each initial window position, generates indices of the window elements</span></span><br><span class="line"></span><br><span class="line">    indices = tf.data.Dataset.<span class="built_in">zip</span>(</span><br><span class="line">        (tf.data.Dataset.<span class="built_in">range</span>(<span class="built_in">len</span>(index)), positions_ds)</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    indices_X = indices.<span class="built_in">map</span>(</span><br><span class="line">        <span class="keyword">lambda</span> i, positions: tf.<span class="built_in">range</span>(</span><br><span class="line">            positions[i] - sequence_length + <span class="number">1</span>,</span><br><span class="line">            positions[i] + <span class="number">1</span>,</span><br><span class="line">        ),</span><br><span class="line">        num_parallel_calls=tf.data.AUTOTUNE,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    indices_Y = indices.<span class="built_in">map</span>(</span><br><span class="line">        <span class="keyword">lambda</span> i, positions: positions[i],</span><br><span class="line">        num_parallel_calls=tf.data.AUTOTUNE,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    dataset_X = sequences_from_indices(X, indices_X)</span><br><span class="line">    dataset_Y = sequences_from_indices(Y, indices_Y)</span><br><span class="line"></span><br><span class="line">    dataset = tf.data.Dataset.<span class="built_in">zip</span>((dataset_X, dataset_Y))</span><br><span class="line">    dataset = dataset.prefetch(tf.data.AUTOTUNE)</span><br><span class="line">    <span class="keyword">if</span> batch_size <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> shuffle:</span><br><span class="line">            <span class="comment"># Shuffle locally at each iteration</span></span><br><span class="line">            dataset = dataset.shuffle(buffer_size=batch_size * <span class="number">8</span>)</span><br><span class="line">        dataset = dataset.batch(</span><br><span class="line">            batch_size</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> shuffle:</span><br><span class="line">            dataset = dataset.shuffle(buffer_size=<span class="number">1024</span>)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">num_samples = <span class="number">10000</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_samples * num_features).reshape(num_samples, num_features)</span><br><span class="line">y = np.arange(num_samples)</span><br><span class="line"></span><br><span class="line">index = np.arange(sequence_length-<span class="number">1</span>, <span class="built_in">len</span>(X))</span><br><span class="line"></span><br><span class="line">dataset = get_sequence_dataset(X,</span><br><span class="line">                               y,</span><br><span class="line">                               index,</span><br><span class="line">                               sequence_length,</span><br><span class="line">                               batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">Xi, yi = dataset.take(<span class="number">1</span>).as_numpy_iterator().<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>这个实现的思路是先在 index 的时候转换成 <code>tf.data</code> 对应的下标迭代 pipeline，然后再根据下标去取数据。</p>
<p>比起一开始的简易实现，这个实现迭代的时候会更快一些（可能是更早被 <code>tf.data</code> 接管了）；但是这个实现还是有一个问题：没有利用到 <strong>可以并行取数据</strong> 的特性。也就是说，取 <code>index[2]</code> 可以跟 <code>index[1]</code> <code>index[0]</code> 的时候同时取的，甚至可以先于 <code>index[1]</code> <code>index[0]</code> 取的，因为这些取数据的过程 <strong>互不干扰</strong>。但是，目前使用的 <code>tf.data</code> 取数据的过程似乎都是串行的，譬如 <code>tf.data.Dataset.from_generator</code> 这个从 generator 来生成数据的，就是假设只能通过一个 <code>next</code> 方法来获取下一批数据。之后的优化应该重点考虑接触这个限制，能够让取数据的过程并行化。</p>
<h3 id="keras-utils-Sequence-实现"><a href="#keras-utils-Sequence-实现" class="headerlink" title="keras.utils.Sequence 实现"></a><code>keras.utils.Sequence</code> 实现</h3><p>之后的实现是继承 <code>keras.util.Sequence</code> 这个类。注意这个类的数据迭代是以 batch 为计量单位的，也就是每次取一个 batch 的数据。需要重写以下方法：</p>
<ul>
<li><code>__len__</code> 这个数据集一共有多少个 batch</li>
<li><code>__getitem__</code> 根据 <code>batch_id</code>，获取对应的批量数据</li>
<li><code>on_epoch_end</code> 在每个 epoch 执行完之后调用，一般是用于负责数据的 shuffle</li>
</ul>
<p>在实现的过程中，注意几点：</p>
<ul>
<li>还是尽可能把 <code>__getitem__</code> 中取数据的逻辑变得简单，越简单越好</li>
<li>预处理的操作可以提前做，譬如放在构造函数里面完成</li>
<li>尽可能利用 numpy 中的向量化运算，譬如根据下标取元素的时候，可以直接根据下标取出所有元素；还有如下特性：</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">A = np.arange(<span class="number">6</span>).reshape(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># array([[0, 1, 2],</span></span><br><span class="line"><span class="comment">#        [3, 4, 5]])</span></span><br><span class="line">B = A[:, [[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>]]]</span><br><span class="line"><span class="comment"># array([[[0, 1],</span></span><br><span class="line"><span class="comment">#         [1, 2]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#        [[3, 4],</span></span><br><span class="line"><span class="comment">#         [4, 5]]])</span></span><br></pre></td></tr></table></figure>
<p>也就是说，我们可以预先生成一个二维的 index（下面的 <code>self.index_sequence</code>），然后利用这个特性去进行索引取出所需要的元素。之所以这样预取，是因为 <code>self.index_sequence</code> 的形状是 <code>(num_index, sequence_length)</code>，跟 <code>X</code> 的量级差不多，所以内存还能装得下（如果装不下的话恐怕又只能在线生成了）</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;VISIBLE_CUDA_DEVICES&#x27;</span>] = <span class="string">&#x27;-1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TSDataset</span>(keras.utils.<span class="type">Sequence</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        X: np.ndarray,</span></span><br><span class="line"><span class="params">        y: np.ndarray,</span></span><br><span class="line"><span class="params">        index: np.ndarray,</span></span><br><span class="line"><span class="params">        sequence_length: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        batch_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        shuffle: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        drop_last: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.X = X.astype(np.float32)</span><br><span class="line">        self.y = y.astype(np.float64)</span><br><span class="line">        self.index = index</span><br><span class="line">        self.sequence_length = sequence_length</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.num_index = <span class="built_in">len</span>(self.index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># drop_last: train set vs test set</span></span><br><span class="line">        self.steps_per_epoch = self.num_index // batch_size</span><br><span class="line">        <span class="keyword">if</span> drop_last <span class="keyword">or</span> self.num_index % batch_size == <span class="number">0</span>:</span><br><span class="line">            self.num_index_in_last_step = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.steps_per_epoch += <span class="number">1</span></span><br><span class="line">            <span class="comment"># append fake data to the end</span></span><br><span class="line">            self.index += self.index[</span><br><span class="line">                : batch_size - self.num_index % batch_size</span><br><span class="line">            ]</span><br><span class="line">            self.num_index_in_last_step = self.num_index % batch_size</span><br><span class="line"></span><br><span class="line">        self.index = np.array(self.index)</span><br><span class="line">        self._get_index_sequence()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_index_sequence</span>(<span class="params">self</span>):</span><br><span class="line">        num_maintaining_index = <span class="built_in">len</span>(self.index)</span><br><span class="line">        self.index_sequence = np.zeros(</span><br><span class="line">            (num_maintaining_index, self.sequence_length), dtype=np.int32</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.sequence_length):</span><br><span class="line">            self.index_sequence[:, i] = self.index + i + <span class="number">1</span> - self.sequence_length</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.steps_per_epoch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        current_batch_id = self.index[</span><br><span class="line">            self.batch_size * index : self.batch_size * (index + <span class="number">1</span>)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        all_indices = self.index_sequence[</span><br><span class="line">            self.batch_size * index : self.batch_size * (index + <span class="number">1</span>), :</span><br><span class="line">        ]</span><br><span class="line">        X_batch = self.X[all_indices, ...]</span><br><span class="line">        y_batch = self.y[current_batch_id]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X_batch, y_batch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            num_maintaining_index = <span class="built_in">len</span>(self.index)</span><br><span class="line">            shuffle_mapping = <span class="built_in">list</span>(<span class="built_in">range</span>(num_maintaining_index))</span><br><span class="line">            np.random.shuffle(shuffle_mapping)</span><br><span class="line">            self.index = self.index[shuffle_mapping]</span><br><span class="line">            self.index_sequence = self.index_sequence[shuffle_mapping, :]</span><br><span class="line"></span><br><span class="line">num_indexs = <span class="number">10000</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_indexs * num_features).reshape(num_indexs, num_features)</span><br><span class="line">y = np.arange(num_indexs)</span><br><span class="line"></span><br><span class="line">index = np.arange(sequence_length-<span class="number">1</span>, <span class="built_in">len</span>(X))</span><br><span class="line"></span><br><span class="line">dataset = TSDataset(X,</span><br><span class="line">                    y,</span><br><span class="line">                    index,</span><br><span class="line">                    sequence_length,</span><br><span class="line">                    batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">Xi, yi = dataset[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>然后在 <code>model.fit</code> 和 <code>model.evaluate</code> 的时候，需要加上 <code>workers=6</code> 以及 <code>max_queue_size=20</code> 参数来并行取数据（这两个数实测下来往更高了调好像就占不到便宜了）</p>
<p>当然具体改进有没有用，以及模型跟占比如何的话，还得结合 tensorflow profiler 来分析：</p>
<p><img src="sequence_profiler.png" alt="keras.utils.Sequence 实现"></p>
<p>对比简易实现，改进已经很 OK 了，但是还有进一步改进的余地</p>
<h2 id="进阶改进"><a href="#进阶改进" class="headerlink" title="进阶改进"></a>进阶改进</h2><p>下面介绍我试了下来，比较有用的改进。</p>
<h3 id="改进-1：调小-batch-size"><a href="#改进-1：调小-batch-size" class="headerlink" title="改进 1：调小 batch_size"></a>改进 1：调小 <code>batch_size</code></h3><p>做到这里之后，工友的一次不经意的尝试揭开了最关键的谜底：之前的配置文件中 <code>batch_size</code> 被设置成了 <code>10000</code>，实际上设置成 <code>2000</code> 之后马上输入的生成时间就会减少很多，WTF……</p>
<p>所以最关键的实际上就是把 <code>batch_size</code> 调小就行了。我们在做 CV 的时候往往会被灌输一个理念，就是 <code>batch_size</code> 尽可能调大到显存炸了为止。这是针对 <code>batch_size &lt;= 128</code> 的情形（一般 CV 最多就这样设 <code>batch_size</code> 顶天了）；但是，当 <code>batch_size</code> 大到一定程度的时候，处理 batch 数据这个环节就会成为拖油瓶。所以最简单的解决策略就是调小 <code>batch_size</code>。<code>batch_size</code> 调小之后的 profiler 长这样，生成数据的时长占比一下子就不见了：</p>
<p><img src="smaller_batch_size.jpg" alt="调小 batch_size 之后"></p>
<h3 id="改进-2：利用-tf-data-Dataset-interleave"><a href="#改进-2：利用-tf-data-Dataset-interleave" class="headerlink" title="改进 2：利用 tf.data.Dataset.interleave"></a>改进 2：利用 <code>tf.data.Dataset.interleave</code></h3><p>用法详见 <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#interleave">文档</a></p>
<p>因为上面的基于 generator 的所有实现，无论何种，tensorflow 底层仅会调用 <code>tf_data_iterator_get_next</code> 来获取数据</p>
<p><img src="data_iterator.png" alt="profile 中可以看到"></p>
<p>而且 profiler 的性能提示中说到可以考虑利用 <code>tf.data.Dataset.interleave</code> 这个 API。原理猜想大概就是把以前的单个 generator 变成若干并行的 generator，然后取数据的时候就轮流用子 generator 来取数据，如下图：</p>
<p><img src="interleave.png" alt="interleave 工作原理猜想"></p>
<p>所以，如果我们不变 tensorflow 的这个 <code>tf_data_iterator_get_next</code> 底层调用，只是将若干个 dataset 以如下的方式“组装”成某个大 dataset，对外（箭头的右边）还是通过 <code>tf_data_iterator_get_next</code> 这个函数来获取下一个 batch 的数据，但是对内可以将这个获取下一个 batch 的操作 “指派” 到具体的子数据集上，结合子数据集又可以通过 prefetch 来提前获取后 N 个迭代的内容，那么就相当于将取数据这个操作“平摊”到子数据集上，也就实现了数据集并行。</p>
<p><em>举个例子：假设单个数据集获取下一个 batch 需要耗时 400ms，如果 “组装” 的并行度为 10 的话，那么理想状态下，“组装” 后的数据集获取下一个 batch 仅需要耗时 40ms</em></p>
<p>代码实现如下：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;VISIBLE_CUDA_DEVICES&#x27;</span>] = <span class="string">&#x27;-1&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TSDataset</span>(keras.utils.<span class="type">Sequence</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        X: np.ndarray,</span></span><br><span class="line"><span class="params">        y: np.ndarray,</span></span><br><span class="line"><span class="params">        index: np.ndarray,</span></span><br><span class="line"><span class="params">        sequence_length: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        batch_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        shuffle: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        drop_last: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.X = X.astype(np.float32)</span><br><span class="line">        self.y = y.astype(np.float64)</span><br><span class="line">        self.index = index</span><br><span class="line">        self.sequence_length = sequence_length</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.num_index = <span class="built_in">len</span>(self.index)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># drop_last: train set vs test set</span></span><br><span class="line">        self.steps_per_epoch = self.num_index // batch_size</span><br><span class="line">        <span class="keyword">if</span> drop_last <span class="keyword">or</span> self.num_index % batch_size == <span class="number">0</span>:</span><br><span class="line">            self.num_index_in_last_step = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.steps_per_epoch += <span class="number">1</span></span><br><span class="line">            <span class="comment"># append fake data to the end</span></span><br><span class="line">            self.index += self.index[</span><br><span class="line">                : batch_size - self.num_index % batch_size</span><br><span class="line">            ]</span><br><span class="line">            self.num_index_in_last_step = self.num_index % batch_size</span><br><span class="line"></span><br><span class="line">        self.index = np.array(self.index)</span><br><span class="line">        self._get_index_sequence()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_index_sequence</span>(<span class="params">self</span>):</span><br><span class="line">        num_maintaining_index = <span class="built_in">len</span>(self.index)</span><br><span class="line">        self.index_sequence = np.zeros(</span><br><span class="line">            (num_maintaining_index, self.sequence_length), dtype=np.int32</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.sequence_length):</span><br><span class="line">            self.index_sequence[:, i] = self.index + i + <span class="number">1</span> - self.sequence_length</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.steps_per_epoch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        current_batch_id = self.index[</span><br><span class="line">            self.batch_size * index : self.batch_size * (index + <span class="number">1</span>)</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        all_indices = self.index_sequence[</span><br><span class="line">            self.batch_size * index : self.batch_size * (index + <span class="number">1</span>), :</span><br><span class="line">        ]</span><br><span class="line">        X_batch = self.X[all_indices, ...]</span><br><span class="line">        y_batch = self.y[current_batch_id]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> X_batch, y_batch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            num_maintaining_index = <span class="built_in">len</span>(self.index)</span><br><span class="line">            shuffle_mapping = <span class="built_in">list</span>(<span class="built_in">range</span>(num_maintaining_index))</span><br><span class="line">            np.random.shuffle(shuffle_mapping)</span><br><span class="line">            self.index = self.index[shuffle_mapping]</span><br><span class="line">            self.index_sequence = self.index_sequence[shuffle_mapping, :]</span><br><span class="line"></span><br><span class="line">num_indexs = <span class="number">10000</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">20</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_indexs * num_features).reshape(num_indexs, num_features)</span><br><span class="line">y = np.arange(num_indexs)</span><br><span class="line"></span><br><span class="line">index = np.arange(sequence_length-<span class="number">1</span>, <span class="built_in">len</span>(X))</span><br><span class="line"></span><br><span class="line">seq = TSDataset(X,</span><br><span class="line">                y,</span><br><span class="line">                index,</span><br><span class="line">                sequence_length,</span><br><span class="line">                batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">output_signature = (</span><br><span class="line">    tf.TensorSpec(</span><br><span class="line">        shape=(batch_size, sequence_length, num_features),</span><br><span class="line">        dtype=tf.float32,</span><br><span class="line">    ),</span><br><span class="line">    tf.TensorSpec(shape=(batch_size,), dtype=tf.float32),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">NUM_PARALLELS = <span class="number">16</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">to_generator</span>(<span class="params">seq: tf.keras.utils.<span class="type">Sequence</span>, generator_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapped_callable</span>():</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(generator_id, <span class="built_in">len</span>(seq), NUM_PARALLELS):</span><br><span class="line">            <span class="keyword">yield</span> seq[i]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wrapped_callable</span><br><span class="line"></span><br><span class="line">dataset = (</span><br><span class="line">    tf.data.Dataset.from_tensor_slices(</span><br><span class="line">        [</span><br><span class="line">            tf.data.Dataset.from_generator(</span><br><span class="line">                to_generator(seq, i), output_signature=output_signature</span><br><span class="line">            ).prefetch(<span class="number">4</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(NUM_PARALLELS)</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    .interleave(</span><br><span class="line">        <span class="keyword">lambda</span> x: x,  <span class="comment"># 直接返回数据集</span></span><br><span class="line">        cycle_length=NUM_PARALLELS,  <span class="comment"># 并行读取的数据集数量</span></span><br><span class="line">        block_length=<span class="number">1</span>,  <span class="comment"># 从每个数据集中连续读取的批次数量</span></span><br><span class="line">        num_parallel_calls=NUM_PARALLELS,  <span class="comment"># 自动调整并行度 tf.data.experimental.AUTOTUNE</span></span><br><span class="line">    )</span><br><span class="line">    .prefetch(NUM_PARALLELS)</span><br><span class="line">)</span><br><span class="line">dataset = dataset.apply(tf.data.experimental.assert_cardinality(<span class="built_in">len</span>(seq)))</span><br><span class="line"></span><br><span class="line">Xi, yi = dataset.take(<span class="number">1</span>).as_numpy_iterator().<span class="built_in">next</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><code>batch_size=10000</code> 的 profiler 如下所示：</p>
<p><img src="interleave_profiler.png" alt="interleave + 简易实现"></p>
<p><img src="interleave_sequence_profiler.png" alt="interleave + keras.utils.Sequence 实现"></p>
<p>可以看到输入耗时有所缓解，但还是有点长（感觉不如调小 <code>batch_size</code> 改进来得更直接）而且有几个坑：</p>
<ol>
<li>有如上图所示的尖刺：如果并行度 * 模型计算一个 batch 的时间 &lt; 吐出一个 batch 数据的时间，那么还是会造成周期性的阻塞；</li>
<li>针对上面一点，一个很自然的想法是增大 <code>tf.data.Dataset.interleave</code> 的并行度；但是实验发现并行度并不能无脑增大，一个原因是下面会说到的 tensorflow 底层的 <code>tf_data_private_threadpool</code> 限制；另一方面是还会带来下面的坑</li>
<li>在理想的情况下，每个子数据集都像“流水线”般地生成数据；但是实际情况会有一些特殊：在取前 <code>NUM_PARALLELS</code> 个数据的时候，会发生阻塞，因为一开始没启动子数据集的 <code>prefetch</code>。感觉这个设定还是跟 tensorflow 的 API 假设有关，而且更杯具的是在每个 epoch 的开头，这个耗时的启动过程总是会重新来过。如下图所示：</li>
</ol>
<p><img src="interleave_analysis.jpg" alt="启动造成了延时"></p>
<h3 id="改进-3：手动维护多进程队列"><a href="#改进-3：手动维护多进程队列" class="headerlink" title="改进 3：手动维护多进程队列"></a>改进 3：手动维护多进程队列</h3><p>在测试 <code>keras.utils.Sequence</code> 的时候我关注到了一点：在 trace viewer 中，下面有一个 <code>tf_data_private_threadpool</code>，猜想应该是 tensorflow 底层维护的、实际负责干活的线程池：</p>
<p><img src="threadpool.png" alt="trace viewer"></p>
<p>按理来说，使用 <code>keras.utils.Sequence</code> 之后，将 <code>workers</code> 往大了调之后，应该 <code>tf_data_private_threadpool</code> 的并行数也该是多多益善的，但是在明显可以往大了再调调效率还有得提高（生成输入的时长占比较高）的背景下，这个并行数就没！动！了！（<code>workers=20</code> 之后这个条目数量还是 2 个的样子）；类似地，在使用 <code>tf.data.Dataset.interleave</code> 之后，并不是一味调高 <code>NUM_PARALLELS</code> 就能增大实际  <code>tf_data_private_threadpool</code> 的并行数。而且，这种并行数的限制肯定不是因为设备的计算资源不够用才导致的。</p>
<p>这里提出一个猜想就是 <strong>可能 tensorflow 内部对于并行度有约束</strong>。虽然搜索了若干对并行度的设置：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads">set_inter_op_parallelism_threads</a></li>
<li><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/data/ThreadingOptions">private_threadpool_size</a></li>
</ul>
<p>但是尝试过后发现没什么改变。然后又去翻源码，翻到了个 <a target="_blank" rel="noopener" href="https://github.com/tensorflow/tensorflow/blob/26b4dfa65d360f2793ad75083c797d57f8661b93/tensorflow/core/protobuf/config.proto#L165">这</a>，难道说 <code>inter_op_parallelism_threads</code> 已经被钦定了？我不理解</p>
<p>所以最后就冒出一个想法：既然你 tensorflow 对于数据获取这一方面做得这么烂，那我就自己维护多进程取数据的过程。</p>
<ul>
<li>把 prefetch 分成 <code>NUM_PARALLELS</code> 个槽，每个槽装 1 个 batch 的数据；</li>
<li>有多个写者（生成数据），具体来说每个写者对一个槽里面写 batch 数据；</li>
<li>有一个读者（读数据），循环读处理好的 batch 数据；</li>
<li>对于每个槽，维护状态，NEW 表示当前槽的数据是最新的，USED 表示当前槽的数据是还没准备好的</li>
<li>对每个槽配置一个锁：无论是读数据还是写数据，都需要先上锁，对数据操作，操作完才能更新对应槽的状态</li>
<li>对象一创建就拉起 <code>NUM_PARALLELS</code> 个写者写数据</li>
</ul>
<p>因为 python GIL 的限制，所以应该被做成多进程的模式；因为数据比较大，所以数据共享采用共享内存。</p>
<p>让 deepseek 糊了一个实现：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> multiprocessing.shared_memory <span class="keyword">import</span> SharedMemory</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态常量</span></span><br><span class="line">USED = <span class="number">0</span></span><br><span class="line">NEW = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ParallelTSDataset</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        X: np.ndarray,</span></span><br><span class="line"><span class="params">        y: np.ndarray,</span></span><br><span class="line"><span class="params">        index: np.ndarray,</span></span><br><span class="line"><span class="params">        sequence_length: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        batch_size: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        shuffle: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        drop_last: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        num_parallels: <span class="built_in">int</span> = <span class="number">4</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="comment"># 原始参数保持</span></span><br><span class="line">        self.X = X.astype(np.float32)</span><br><span class="line">        self.y = y.astype(np.float32)</span><br><span class="line">        self.original_index = index.copy()</span><br><span class="line">        self.sequence_length = sequence_length</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.shuffle = shuffle</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line">        self.num_parallels = num_parallels</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 共享内存管理</span></span><br><span class="line">        self.manager = mp.Manager()</span><br><span class="line">        self.slots = self.manager.<span class="built_in">list</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算数据形状</span></span><br><span class="line">        self.x_shape = (batch_size, sequence_length, X.shape[<span class="number">1</span>])</span><br><span class="line">        self.y_shape = (batch_size,)</span><br><span class="line">        self.x_dtype = np.dtype(np.float32)</span><br><span class="line">        self.y_dtype = np.dtype(np.float32)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化共享槽</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_parallels):</span><br><span class="line">            x_shm = SharedMemory(create=<span class="literal">True</span>, size=np.prod(self.x_shape)*self.x_dtype.itemsize)</span><br><span class="line">            y_shm = SharedMemory(create=<span class="literal">True</span>, size=np.prod(self.y_shape)*self.y_dtype.itemsize)</span><br><span class="line">            </span><br><span class="line">            self.slots.append(&#123;</span><br><span class="line">                <span class="string">&#x27;x_shm&#x27;</span>: x_shm.name,</span><br><span class="line">                <span class="string">&#x27;y_shm&#x27;</span>: y_shm.name,</span><br><span class="line">                <span class="string">&#x27;state&#x27;</span>: self.manager.Value(<span class="string">&#x27;i&#x27;</span>, USED),</span><br><span class="line">                <span class="string">&#x27;lock&#x27;</span>: self.manager.Lock(),</span><br><span class="line">                <span class="string">&#x27;ready&#x27;</span>: self.manager.Event()</span><br><span class="line">            &#125;)</span><br><span class="line">            x_shm.close()</span><br><span class="line">            y_shm.close()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 初始化索引相关</span></span><br><span class="line">        self._reset_indexes()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 启动写进程</span></span><br><span class="line">        self.writers = []</span><br><span class="line">        <span class="keyword">for</span> slot_idx <span class="keyword">in</span> <span class="built_in">range</span>(num_parallels):</span><br><span class="line">            p = mp.Process(target=self._writer_worker, args=(slot_idx,), daemon=<span class="literal">True</span>)</span><br><span class="line">            p.start()</span><br><span class="line">            self.writers.append(p)</span><br><span class="line">            </span><br><span class="line">        self.reader_idx = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_reset_indexes</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;初始化/重置索引系统&quot;&quot;&quot;</span></span><br><span class="line">        self.index = self.original_index.copy()</span><br><span class="line">        self.num_index = <span class="built_in">len</span>(self.index)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算 epoch 步数</span></span><br><span class="line">        self.steps_per_epoch = self.num_index // self.batch_size</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> (self.num_index % self.batch_size == <span class="number">0</span> <span class="keyword">or</span> self.drop_last):</span><br><span class="line">            self.steps_per_epoch += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 生成索引序列</span></span><br><span class="line">        self.index_sequence = np.zeros(</span><br><span class="line">            (self.num_index, self.sequence_length), dtype=np.int32</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.sequence_length):</span><br><span class="line">            self.index_sequence[:, i] = self.index + i + <span class="number">1</span> - self.sequence_length</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_writer_worker</span>(<span class="params">self, slot_idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;写进程工作函数&quot;&quot;&quot;</span></span><br><span class="line">        slot = self.slots[slot_idx]</span><br><span class="line">        x_shm = SharedMemory(name=slot[<span class="string">&#x27;x_shm&#x27;</span>])</span><br><span class="line">        y_shm = SharedMemory(name=slot[<span class="string">&#x27;y_shm&#x27;</span>])</span><br><span class="line">        </span><br><span class="line">        x_arr = np.ndarray(self.x_shape, self.x_dtype, x_shm.buf)</span><br><span class="line">        y_arr = np.ndarray(self.y_shape, self.y_dtype, y_shm.buf)</span><br><span class="line">        batch_offset = slot_idx * self.batch_size</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">                <span class="keyword">with</span> slot[<span class="string">&#x27;lock&#x27;</span>]:</span><br><span class="line">                    <span class="keyword">if</span> slot[<span class="string">&#x27;state&#x27;</span>].value == USED:</span><br><span class="line">                        <span class="comment"># 填充 X 数据</span></span><br><span class="line">                        x_data = self.X[self.index_sequence[batch_offset:batch_offset+self.batch_size]]</span><br><span class="line">                        x_arr[:] = x_data</span><br><span class="line">                        </span><br><span class="line">                        <span class="comment"># 填充 y 数据</span></span><br><span class="line">                        y_data = self.y[self.index[batch_offset:batch_offset+self.batch_size]]</span><br><span class="line">                        y_arr[:] = y_data</span><br><span class="line">                        </span><br><span class="line">                        slot[<span class="string">&#x27;state&#x27;</span>].value = NEW</span><br><span class="line">                        slot[<span class="string">&#x27;ready&#x27;</span>].<span class="built_in">set</span>()</span><br><span class="line">                        batch_offset += self.num_parallels * self.batch_size</span><br><span class="line">                </span><br><span class="line">                time.sleep(<span class="number">0.01</span>)  <span class="comment"># 防止 CPU 空转</span></span><br><span class="line">        <span class="keyword">finally</span>:</span><br><span class="line">            x_shm.close()</span><br><span class="line">            y_shm.close()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.steps_per_epoch</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;实现预取逻辑&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            slot = self.slots[self.reader_idx]</span><br><span class="line">            self.reader_idx = (self.reader_idx + <span class="number">1</span>) % self.num_parallels</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> slot[<span class="string">&#x27;ready&#x27;</span>].is_set():</span><br><span class="line">                <span class="keyword">with</span> slot[<span class="string">&#x27;lock&#x27;</span>]:</span><br><span class="line">                    <span class="keyword">if</span> slot[<span class="string">&#x27;state&#x27;</span>].value == NEW:</span><br><span class="line">                        <span class="comment"># 从共享内存读取</span></span><br><span class="line">                        x_shm = SharedMemory(name=slot[<span class="string">&#x27;x_shm&#x27;</span>])</span><br><span class="line">                        y_shm = SharedMemory(name=slot[<span class="string">&#x27;y_shm&#x27;</span>])</span><br><span class="line">                        </span><br><span class="line">                        <span class="keyword">try</span>:</span><br><span class="line">                            X_batch = np.copy(np.ndarray(</span><br><span class="line">                                self.x_shape, </span><br><span class="line">                                self.x_dtype, </span><br><span class="line">                                x_shm.buf</span><br><span class="line">                            ))</span><br><span class="line">                            y_batch = np.copy(np.ndarray(</span><br><span class="line">                                self.y_shape,</span><br><span class="line">                                self.y_dtype,</span><br><span class="line">                                y_shm.buf</span><br><span class="line">                            ))</span><br><span class="line">                        <span class="keyword">finally</span>:</span><br><span class="line">                            x_shm.close()</span><br><span class="line">                            y_shm.close()</span><br><span class="line">                        </span><br><span class="line">                        slot[<span class="string">&#x27;state&#x27;</span>].value = USED</span><br><span class="line">                        slot[<span class="string">&#x27;ready&#x27;</span>].clear()</span><br><span class="line">                        <span class="keyword">return</span> X_batch, y_batch</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                time.sleep(<span class="number">0.01</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;epoch结束时打乱数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> self.shuffle:</span><br><span class="line">            shuffle_indices = np.random.permutation(<span class="built_in">len</span>(self.index))</span><br><span class="line">            self.index = self.index[shuffle_indices]</span><br><span class="line">            self.index_sequence = self.index_sequence[shuffle_indices]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cleanup</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;清理资源&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> self.writers:</span><br><span class="line">            p.terminate()</span><br><span class="line">        <span class="keyword">for</span> slot <span class="keyword">in</span> self.slots:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                x_shm = SharedMemory(name=slot[<span class="string">&#x27;x_shm&#x27;</span>])</span><br><span class="line">                x_shm.close()</span><br><span class="line">                x_shm.unlink()</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                y_shm = SharedMemory(name=slot[<span class="string">&#x27;y_shm&#x27;</span>])</span><br><span class="line">                y_shm.close()</span><br><span class="line">                y_shm.unlink()</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试代码保持不变</span></span><br><span class="line">num_indexs = <span class="number">20</span></span><br><span class="line">num_features = <span class="number">10</span></span><br><span class="line">sequence_length = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">3</span></span><br><span class="line">NUM_PARALLELS = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">X = np.arange(num_indexs * num_features).reshape(num_indexs, num_features)</span><br><span class="line">y = np.arange(num_indexs)</span><br><span class="line"></span><br><span class="line">index = np.arange(sequence_length-<span class="number">1</span>, <span class="built_in">len</span>(X))</span><br><span class="line"></span><br><span class="line">dataset = ParallelTSDataset(</span><br><span class="line">    X,</span><br><span class="line">    y,</span><br><span class="line">    index,</span><br><span class="line">    sequence_length,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    num_parallels=NUM_PARALLELS</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    Xi, yi = dataset[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;Xi = &#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;yi = &#125;</span>&#x27;</span>)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    dataset.cleanup()</span><br></pre></td></tr></table></figure>
<p><em>注意：在 linux 系统中可以使用多个子进程加载数据，而在 windows 系统中不能这样做。如果要在 windows 系统中使用的话，创建子进程的代码必须要在 <code>if __name__ == &#39;__main__&#39;:</code> 下面才行</em></p>
<p>此时注意：因为已经使用了一个循环队列来控制数据的读写，所以数据集的生成相当于是一个 iterator，只关注 next 了，<code>__getitem__</code> 方法的 <code>index</code> 参数没有真正被使用，而是根据调用次数来绝对的 <code>__getitem__</code> 的返回值，所以理论上也可以向上暴露 generator。</p>
<p>但是有一个问题始终是存在的，就是调用 <code>model.fit</code> 的时候，每个 epoch 都会重新创建一个数据集对象，prefetch 之类的占便宜手法不能跨 epoch 应用（这点很烦，这样就解释了为什么 <code>from_generator</code> 是传入一个 callable，它内部每个 epoch 会调用 <code>__call__</code> 方法）。这点目前没找到解决方法，不过似乎再往下钻研性价比过低了，就此打住，告一段落。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://zm-j.github.io">ZM-J</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://zm-j.github.io/2025/02/14/dataset-building/">https://zm-j.github.io/2025/02/14/dataset-building/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/keras/">keras</a><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/07/14/cryptoctf-2025-summary/" title="CryptoCTF 2025 战果速报"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">CryptoCTF 2025 战果速报</div></div></a></div><div class="next-post pull-right"><a href="/2024/12/10/entropy/" title="再看交叉熵"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">再看交叉熵</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/06/14/keras-issues/" title="不定时更新的 Keras 踩坑记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-06-14</div><div class="title">不定时更新的 Keras 踩坑记</div></div></a></div><div><a href="/2024/09/20/keras-model-building/" title="如何科学地在 keras 中构建模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-20</div><div class="title">如何科学地在 keras 中构建模型</div></div></a></div><div><a href="/2024/10/25/convert-keras-models-to-their-tensorflow-counterparts/" title="如何将 keras 模型转换成同样的 pytorch 模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-25</div><div class="title">如何将 keras 模型转换成同样的 pytorch 模型</div></div></a></div><div><a href="/2024/04/19/tensorflow-profile-issues/" title="Tensorflow Profiler 踩坑记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-19</div><div class="title">Tensorflow Profiler 踩坑记</div></div></a></div><div><a href="/2024/12/10/entropy/" title="再看交叉熵"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="title">再看交叉熵</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ZM-J</div><div class="author-info__description">丧失年轻，勿失年华</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">46</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ZM-J"><i class="fab fa-github"></i><span>信春哥</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://www.zhihu.com/people/ZM_________J" target="_blank" title="Zhihu"><i class="fab fa-zhihu" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">春哥纯爷们，铁血真汉子。人民好兄弟，父亲好儿子。拳上能站人，臂上能走马！夜御十女枪不倒，菊花百战色仍红！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E5%BC%80%E5%A7%8B%E7%9A%84%E5%81%9A%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">一开始的做法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E6%98%93%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.1.</span> <span class="toc-text">简易实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">性能分析方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9A%B4%E5%8A%9B%E5%AE%9E%E7%8E%B0"><span class="toc-number">2.3.</span> <span class="toc-text">暴力实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B"><span class="toc-number">3.</span> <span class="toc-text">改进</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AD%94%E6%94%B9-keras-utils-timeseries-dataset-from-array"><span class="toc-number">3.1.</span> <span class="toc-text">魔改 keras.utils.timeseries_dataset_from_array</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#keras-utils-Sequence-%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.2.</span> <span class="toc-text">keras.utils.Sequence 实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E6%94%B9%E8%BF%9B"><span class="toc-number">4.</span> <span class="toc-text">进阶改进</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B-1%EF%BC%9A%E8%B0%83%E5%B0%8F-batch-size"><span class="toc-number">4.1.</span> <span class="toc-text">改进 1：调小 batch_size</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B-2%EF%BC%9A%E5%88%A9%E7%94%A8-tf-data-Dataset-interleave"><span class="toc-number">4.2.</span> <span class="toc-text">改进 2：利用 tf.data.Dataset.interleave</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B-3%EF%BC%9A%E6%89%8B%E5%8A%A8%E7%BB%B4%E6%8A%A4%E5%A4%9A%E8%BF%9B%E7%A8%8B%E9%98%9F%E5%88%97"><span class="toc-number">4.3.</span> <span class="toc-text">改进 3：手动维护多进程队列</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/30/cryptoctf-2025-head-scratcher/" title="CryptoCTF 2025 head scratcher 分类 团队解题 writeup">CryptoCTF 2025 head scratcher 分类 团队解题 writeup</a><time datetime="2025-09-30T10:14:00.000Z" title="Created 2025-09-30 18:14:00">2025-09-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/09/cryptoctf-2025-brain-buster/" title="CryptoCTF 2025 brain buster 分类 团队解题 writeup">CryptoCTF 2025 brain buster 分类 团队解题 writeup</a><time datetime="2025-09-09T07:04:00.000Z" title="Created 2025-09-09 15:04:00">2025-09-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/09/02/cryptoctf-2025-tough-cookie-3/" title="CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之三">CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之三</a><time datetime="2025-09-02T09:28:00.000Z" title="Created 2025-09-02 17:28:00">2025-09-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/13/cryptoctf-2025-tough-cookie-2/" title="CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之二">CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之二</a><time datetime="2025-08-13T09:52:00.000Z" title="Created 2025-08-13 17:52:00">2025-08-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/04/cryptoctf-2025-tough-cookie-1/" title="CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之一">CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之一</a><time datetime="2025-08-04T03:54:00.000Z" title="Created 2025-08-04 11:54:00">2025-08-04</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By ZM-J</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="Chat"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23lib8keprJGNom7Yt',
      clientSecret: 'ec292b94fcfc3c36860e77622a4a4b37639c983a',
      repo: 'ZM-J.github.io',
      owner: 'ZM-J',
      admin: ['ZM-J'],
      id: 'cb1f73fca4bc9e803b1389de6f29a93c',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>