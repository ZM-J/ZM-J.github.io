<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>不定时更新的 Keras 踩坑记 | 春勃</title><meta name="author" content="ZM-J"><meta name="copyright" content="ZM-J"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="众所周知，一般 research 里面所使用的炼丹框架以 PyTorch 居多。然而在工业界的模型部署中，TensorFlow 因能较好地支持多 GPU 的特性而广受青睐。 其中，Keras 以 TensorFlow 为后端（之前的 Keras 版本也能以 Theano、MXNet 等为后端），对 TensorFlow 的诸多 API 进行了封装，为模型的部署进一步降低了门槛。并且，TensorF">
<meta property="og:type" content="article">
<meta property="og:title" content="不定时更新的 Keras 踩坑记">
<meta property="og:url" content="https://zm-j.github.io/2022/06/14/keras-issues/index.html">
<meta property="og:site_name" content="春勃">
<meta property="og:description" content="众所周知，一般 research 里面所使用的炼丹框架以 PyTorch 居多。然而在工业界的模型部署中，TensorFlow 因能较好地支持多 GPU 的特性而广受青睐。 其中，Keras 以 TensorFlow 为后端（之前的 Keras 版本也能以 Theano、MXNet 等为后端），对 TensorFlow 的诸多 API 进行了封装，为模型的部署进一步降低了门槛。并且，TensorF">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zm-j.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2022-06-14T08:05:00.000Z">
<meta property="article:modified_time" content="2024-09-20T08:00:01.167Z">
<meta property="article:author" content="ZM-J">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="keras">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zm-j.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://zm-j.github.io/2022/06/14/keras-issues/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '不定时更新的 Keras 踩坑记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-09-20 16:00:01'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="春勃"><span class="site-name">春勃</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">不定时更新的 Keras 踩坑记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-06-14T08:05:00.000Z" title="Created 2022-06-14 16:05:00">2022-06-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-09-20T08:00:01.167Z" title="Updated 2024-09-20 16:00:01">2024-09-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%B7%A5%E5%9C%B0%E9%9A%8F%E7%AC%94/">工地随笔</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="不定时更新的 Keras 踩坑记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>众所周知，一般 research 里面所使用的炼丹框架以 PyTorch 居多。然而在工业界的模型部署中，TensorFlow 因能较好地支持多 GPU 的特性而广受青睐。</p>
<p>其中，Keras 以 TensorFlow 为后端（之前的 Keras 版本也能以 Theano、MXNet 等为后端），对 TensorFlow 的诸多 API 进行了封装，为模型的部署进一步降低了门槛。并且，TensorFlow 也把 Keras 集成进来，作为 TensorFlow 的一部分。</p>
<p>俺也是最近才系统性地接触到 Keras，之前都是 PyTorch 居多，用 TensorFlow 或者 Keras 仅仅是在复现其他人的工作上会用到。所以这不可避免地就会踩到很多坑。在这里记录下来，以方便之后遇到类似坑的时候，能快速反应下来是出现了什么问题。本人机器配置如下：</p>
<ul>
<li>操作系统：Windows 11 家庭中文版 21H2</li>
<li>显卡：NVIDIA GeForce RTX 3060</li>
<li>Python 版本：3.9.7</li>
<li>CUDA 版本：11.6（可能就是因为这个 11.6 带来了之后的一系列巨坑……现在跑去 NVIDIA 官网下 CUDA，它会首退给你 11.6，但是未必最新的就是最好的，不想折腾的话还是用 11.2 之类的稳定版本……）</li>
<li>TensorFlow 版本：2.8.0</li>
<li>Keras 版本：2.8.0</li>
</ul>
<h2 id="keras-Sequential-中-model-build-的问题"><a href="#keras-Sequential-中-model-build-的问题" class="headerlink" title="keras.Sequential 中 model.build 的问题"></a>keras.Sequential 中 model.build 的问题</h2><p>报错信息如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">return int(fan_in), int(fan_out)</span><br><span class="line">TypeError: int() argument must be a string, a bytes-like object or a number, not &#x27;NoneType&#x27;</span><br></pre></td></tr></table></figure>
<p>我们以一个简单的 LSTM 为例，用<code>keras.Sequential</code>来构造：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(keras.layers.LSTM(<span class="number">64</span>, return_sequences=<span class="literal">False</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;ReLU&quot;</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">1</span>))</span><br><span class="line">model.build(input_shape=(<span class="literal">None</span>, <span class="number">10</span>, <span class="number">12</span>))</span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br></pre></td></tr></table></figure>
<p>这里我们也就成功通过<code>build</code>，构建了一个序列长度为 10，特征维度为 12 的 LSTM。并且可以在后面进行正常的训练和测试。<code>model.summary()</code>结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Model: &quot;sequential&quot;</span><br><span class="line">_________________________________________________________________</span><br><span class="line"> Layer (type)                Output Shape              Param #</span><br><span class="line">=================================================================</span><br><span class="line"> lstm (LSTM)                 (None, 64)                19712</span><br><span class="line"></span><br><span class="line"> dense (Dense)               (None, 32)                2080</span><br><span class="line"></span><br><span class="line"> dense_1 (Dense)             (None, 1)                 33</span><br><span class="line"></span><br><span class="line">=================================================================</span><br><span class="line">Total params: 21,825</span><br><span class="line">Trainable params: 21,825</span><br><span class="line">Non-trainable params: 0</span><br><span class="line">_________________________________________________________________</span><br></pre></td></tr></table></figure>
<p>但是，在模型的保存和读取测试中，出现了上述的报错。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">&#x27;./checkpoint/test.h5&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line">model = keras.models.load_model(<span class="string">&#x27;./checkpoint/test.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>经过查询，用 Sequential 的话，我们在 LSTM 的定义中要确定好<code>input_shape</code>，而非在最后用<code>model.build()</code>。具体细节可以看到下面的 Stack Overflow：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/64829642/keras-load-model-typeerror-int-argument-nonetype">https://stackoverflow.com/questions/64829642/keras-load-model-typeerror-int-argument-nonetype</a></p>
</blockquote>
<p>里面提到了可以用<code>model.to_json()</code>查看模型的细节。具体操作的结果是：</p>
<ul>
<li><code>model.build()</code>之后，<code>input_shape</code>为<code>[null, 10, 12]</code></li>
</ul>
<p>但是在模型完成了训练和验证之后，也就是在<code>model.save()</code>之前，<code>input_shape</code>变成了<code>[null, null, null]</code>。这就确实是 Stack Overflow 的问题。直接在 LSTM 的定义里面说明<code>input_shape=(10, 12)</code>就能解决问题。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(keras.layers.LSTM(<span class="number">64</span>, return_sequences=<span class="literal">False</span>, input_shape=(<span class="number">10</span>, <span class="number">12</span>)))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;ReLU&quot;</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(model.summary())</span><br></pre></td></tr></table></figure>
<h2 id="训练时-checkpoint-回调不停地报关于-LSTMcell-的-warning"><a href="#训练时-checkpoint-回调不停地报关于-LSTMcell-的-warning" class="headerlink" title="训练时 checkpoint 回调不停地报关于 LSTMcell 的 warning"></a>训练时 checkpoint 回调不停地报关于 LSTMcell 的 warning</h2><p>这个应该是没有将存储路径写成 hdf5 的后缀。直接改一下就行了</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_path = <span class="string">&#x27;./checkpoint/&#x27;</span> <span class="comment"># NO</span></span><br><span class="line">checkpoint_path = <span class="string">&#x27;./checkpoint/weights.&#123;epoch:02d&#125;.h5&#x27;</span> <span class="comment"># YES</span></span><br><span class="line">cp_callback = keras.callbacks.ModelCheckpoint(</span><br><span class="line">            checkpoint_path, save_weights_only=<span class="literal">False</span>, save_best_only=<span class="literal">True</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="当-model-fit-的训练集使用-generator-时停不下来"><a href="#当-model-fit-的训练集使用-generator-时停不下来" class="headerlink" title="当 model.fit 的训练集使用 generator 时停不下来"></a>当 model.fit 的训练集使用 generator 时停不下来</h2><p>众所周知，<code>model.fit</code>方法能接受的数据集可以是<code>list</code>、<code>np.array</code>、<code>pd.DataFrame</code>，其中后两者都会默认第一维为 batch 的索引。</p>
<p>然而，在实际的应用场景中，我们的数据集本身可能比较大，没法一次性装到内存中，于是<code>model.fit</code>也支持我们用<code>generator</code>作为模型的输入。如下就是一个简单的<code>generator</code>例子：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_generator</span>():</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        batch = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            batch.append(i)</span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">len</span>(batch) == <span class="number">3</span>):</span><br><span class="line">                <span class="keyword">yield</span> batch</span><br><span class="line">                batch = []</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(batch) &gt; <span class="number">0</span>):</span><br><span class="line">            <span class="keyword">yield</span> batch</span><br><span class="line">            batch = []</span><br></pre></td></tr></table></figure>
<p>这就会得到一个<code>generator</code>，并且可以通过<code>__next__()</code>方法得到一个批次的训练数据。</p>
<p>然后送到<code>model.fit</code>中：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_generator,</span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">          validation_data=val_generator)</span><br></pre></td></tr></table></figure>
<p>这样会发现模型会一直在第一个 epoch 中训练，并且预估还需时间为<code>nan</code>。这是因为，<strong>如此定义的 generator 会一直产生样本。model.fit 在外部调用时并不清楚该 generator 会生成多少样本。</strong></p>
<p>所以，我们还需要在<code>model.fit</code>中加入一个<code>steps_per_epoch</code>参数，用来指示一轮有多少个批次。这可以通过简单的计算得来（要保留最后一个批次就取上整，不保留最后一个批次就取下整，参考<code>DataLoader</code>中的<code>drop_last</code>参数）。类似地，加入一个<code>validation_steps</code>来指示验证集一轮有多少个批次。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_generator,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          steps_per_epoch=steps_per_epoch,</span><br><span class="line">          validation_data=val_generator,</span><br><span class="line">          validation_steps=validation_steps)</span><br></pre></td></tr></table></figure>
<h2 id="当-model-fit-的训练集使用-generator-时不能多线程取数据"><a href="#当-model-fit-的训练集使用-generator-时不能多线程取数据" class="headerlink" title="当 model.fit 的训练集使用 generator 时不能多线程取数据"></a>当 model.fit 的训练集使用 generator 时不能多线程取数据</h2><p>当我们需要用到<code>generator</code>来作为训练集和验证集的输入时，一般都是因为不能直接将一整个训练集装进内存（否则，我们完全可以用更简单的<code>np.array</code>来做）。此时，我们 CPU 的计算资源往往不会是计算瓶颈。因此，我们寄希望于利用多线程读取训练数据的方式，来加速训练。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_generator,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          steps_per_epoch=steps_per_epoch,</span><br><span class="line">          validation_data=val_generator,</span><br><span class="line">          validation_steps=validation_steps,</span><br><span class="line">          workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>然而，这会导致报错，因为 Keras 无法信任我们传进来的 generator 是线程安全的。所以，我们需要另谋他法。</p>
<p>这里我们用到的是继承<code>keras.utils.Sequence</code>这个类。和 PyTorch 里面我们继承<code>torch.utils.data.Dataset</code>一样，我们也需要重写一些方法：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DataGenerator</span>(keras.utils.<span class="type">Sequence</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data, batch_size</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(DataGenerator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.data = data</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.batch_num = (data.shape[<span class="number">0</span>] + batch_size - <span class="number">1</span>) // batch_size</span><br><span class="line">        self.on_epoch_end()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.batch_num</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        data_batch = self.data[index*self.batch_size:(index+<span class="number">1</span>)*self.batch_size]</span><br><span class="line">        X_batch = data_batch[..., :-<span class="number">1</span>]</span><br><span class="line">        y_batch = data_batch[..., -<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回一个批次</span></span><br><span class="line">        <span class="keyword">return</span> X_batch, y_batch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 训练集和测试集在每轮训练（测试）的随机性来源于此方法的实现</span></span><br><span class="line">        np.random.shuffle(self.train_dataset)</span><br></pre></td></tr></table></figure>
<p>于是我们就可以愉快地实现训练时利用多线程取数据了，并且也不需要<code>steps_per_epoch</code>和<code>validation_steps</code>参数（一轮多少批次已经由<code>__len__()</code>方法得到）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.fit(train_generator,</span><br><span class="line">          epochs=<span class="number">20</span>,</span><br><span class="line">          validation_data=val_generator,</span><br><span class="line">          workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<h2 id="cuDNN-不能加载-dll"><a href="#cuDNN-不能加载-dll" class="headerlink" title="cuDNN 不能加载 dll"></a>cuDNN 不能加载 dll</h2><p>在使用 LSTM 的时候，一般不会出现这个问题。</p>
<p>但是在使用卷积层的时候，例如<code>Conv1D</code>，可能会遇到如下报错：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Could not load library cudnn_cnn_infer64_8.dll. Error code 193</span><br></pre></td></tr></table></figure>
<p>但是我已经明明将 cuDNN 中的所有文件复制到 CUDA 文件夹下了，仍然找不到。</p>
<p>后面折腾了一通，发现 NVIDIA 官网推 cuDNN 也是推的最新版 8.4.0。但是似乎 TensorFlow 和 Keras 并不支持这么新的 cuDNN。所以才会报错。</p>
<p>当我们再次查询 TensorFlow 的推荐 CUDA 和 cuDNN 版本：</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/install/source_windows?hl=en#gpu">https://www.tensorflow.org/install/source_windows?hl=en#gpu</a></p>
</blockquote>
<p>发现推荐的 CUDA 和 cuDNN 版本分别为 11.2 和 8.1。</p>
<p>所以我们重新到 NVIDIA 官网上下一个低版本的 cuDNN。看到 8.2.0 是最低的支持 11.x 的 cuDNN 版本，果断下载、覆盖。嘿，您猜怎么着？好了！</p>
<p>所以关键就是 CUDA 和 cuDNN 版本不是越新越好，还是得考虑与 TensorFlow 和 Keras 的适配性。</p>
<p>当然 30 系显卡貌似只能装 11.x 的 CUDA，是时候和 TensorFlow 1.x say goodbye 了。</p>
<blockquote>
<p>和所有的 1.x 说拜拜<br>和所有的 2.x 说嗨嗨</p>
</blockquote>
<h2 id="关于-XLA"><a href="#关于-XLA" class="headerlink" title="关于 XLA"></a>关于 XLA</h2><p>在模型的编译中，我们可以在<a target="_blank" rel="noopener" href="https://keras.io/api/models/model_training_apis/">官方文档</a>看到有个 <code>jit_compile</code> 的可选项，其取值默认为 <code>auto</code>。</p>
<p>看了下面的描述，我一开始以为 <code>jit_compile=True</code> 能提高 GRU 模型的效率，但是后面发现会有很多问题：</p>
<ol>
<li><p><strong>模型的运算效率上并没有得到优化</strong>，反而还在做负优化；</p>
</li>
<li><p>模型可能会<strong>意外触发报错</strong>。这是我在数据迭代的时候打印出当前数据的 index，结果如下：</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">index = 45278</span><br><span class="line">index = 45279</span><br><span class="line">2024-04-03 16:50:32.020688: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplicat.;ion. This will only be logged once.</span><br><span class="line">index = 45280</span><br><span class="line">corrupted double-linked list</span><br><span class="line">index = 45281</span><br><span class="line">index = 45282</span><br></pre></td></tr></table></figure>
<p>然后训练报错推出。当时想着纯 python 代码，哪里有可能涉及到啥双向链表，那必然是 keras 或者 tensorflow 的底层代码弄出来的活儿。那哥们这半吊子也不可能真去嗯啃 tensorflow 的 C++ 源码吧。关键是还在那调半天还没有发现问题，后面才问了工友，结果工友发现了这问题。</p>
<p>另一次报错的内容更加直接：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2024-04-07 18:04:00.859694: E tensorflow/compiler/xla/status_macros.cc:57] INTERNAL: RET_CHECK failure (tensorflow/compiler/xla/service/gpu/gpu_executable_run_options.cc:72)</span><br><span class="line"> 0 &lt;= local_device_ordinal &amp;&amp; local_device_ordinal &lt; gpu_global_device_ids-&gt;size()</span><br><span class="line">*** Begin stack trace ***</span><br><span class="line">        tensorflow::CurrentStackTrace[abi:cxx11]()</span><br><span class="line">        xla::status_macros::MakeErrorStream::Impl::GetStatus()</span><br></pre></td></tr></table></figure>
<ol>
<li>在训练的过程中，模型可能发生<strong>内存泄漏</strong>。具体的发现是通过加了一个回调来每轮开始和结束的内存使用量：</li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/keras-team/keras/issues/15887#issuecomment-1010096128</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> psutil</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> loguru <span class="keyword">import</span> logger</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryUsageCallback</span>(keras.callbacks.Callback):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    Monitor memory usage on epoch begin and end.</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_begin</span>(<span class="params">self, epoch, logs=<span class="literal">None</span></span>):</span><br><span class="line">        logger.debug(<span class="string">&#x27;**Epoch &#123;&#125;**&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>))</span><br><span class="line">        logger.debug(<span class="string">&#x27;Memory usage on epoch begin: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(psutil.Process(os.getpid()).memory_info().rss))  <span class="comment"># nopep8</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_epoch_end</span>(<span class="params">self, epoch, logs=<span class="literal">None</span></span>):</span><br><span class="line">        logger.debug(<span class="string">&#x27;Memory usage on epoch end:   &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(psutil.Process(os.getpid()).memory_info().rss))  <span class="comment"># nopep8</span></span><br></pre></td></tr></table></figure>
<p>然后在训练的时候带上这个 callback 即可：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">memory_usage_callback = MemoryUsageCallback()</span><br><span class="line">callbacks = [</span><br><span class="line">    early_stopping_callback,</span><br><span class="line">    reduce_lr_on_plateau_callback,</span><br><span class="line">    model_checkpoint_callback,</span><br><span class="line">    memory_usage_callback</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>就可以监控到模型训练过程中每个 epoch 开始和结束时的内存使用情况。</p>
<p>不多说了，看看下面的训练日志吧：</p>
<img src="/2022/06/14/keras-issues/memory.png" class="" title="蹦瞎卡拉卡">
<p>可以看到<strong>内存使用量几乎随 epoch 线性增长！</strong>这是多个 epoch 训练时绝对不能接受的！（事实上我们期待内存使用量应该是恒定的）</p>
<p>然后我去找了下相关 keras 的 issue：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/keras-team/keras/issues/19071">https://github.com/keras-team/keras/issues/19071</a></p>
<p>_这里多一句嘴，把 XLA 关了之后，内存占用也会随 epoch 增加有些微的增长，虽然无伤大雅，但是也表明说不定哪里就藏着一些内存泄露……_</p>
<p>后面工友对 XLA 的经验是：</p>
<blockquote>
<p>之前测过这玩意，基本上没啥用，没想到还导致性能倒退[doge]</p>
</blockquote>
<p>所以他对我所给出的人生经验就是：</p>
<blockquote>
<p>对于不熟悉的功能/框架/特性，需要<strong>谨慎引入</strong></p>
</blockquote>
<h2 id="更改模型里面层的名称"><a href="#更改模型里面层的名称" class="headerlink" title="更改模型里面层的名称"></a>更改模型里面层的名称</h2><p>这个事情本来的需求是想在模型构建的时候嵌入一个 metadata，但是呢 keras 模型本身是没有预留一个类似于 metadata 之类的字段的。后面发现如果是只要嵌一个 metadata 的话，其实就直接嵌入到层的 <code>name</code> 字段里面就行了。于是某些 stackoverflow 上的解决方法就是：</p>
<p><del>之后如果需要增加 metadata 内容的话还得通过另外 dump 个 pickle 对象的方式来搞</del></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://zm-j.github.io">ZM-J</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://zm-j.github.io/2022/06/14/keras-issues/">https://zm-j.github.io/2022/06/14/keras-issues/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/keras/">keras</a><a class="post-meta__tags" href="/tags/tensorflow/">tensorflow</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2022/11/21/python-multiprocessing/" title="python multiprocessing 多进程踩坑"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">python multiprocessing 多进程踩坑</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2024/09/20/keras-model-building/" title="如何科学地在 keras 中构建模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-20</div><div class="title">如何科学地在 keras 中构建模型</div></div></a></div><div><a href="/2024/10/25/convert-keras-models-to-their-tensorflow-counterparts/" title="如何将 keras 模型转换成同样的 pytorch 模型"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-10-25</div><div class="title">如何将 keras 模型转换成同样的 pytorch 模型</div></div></a></div><div><a href="/2025/02/14/dataset-building/" title="如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-14</div><div class="title">如何构建高效时序 Keras 数据集：以 tf.data pipeline 分析为例</div></div></a></div><div><a href="/2024/04/19/tensorflow-profile-issues/" title="Tensorflow Profiler 踩坑记"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-19</div><div class="title">Tensorflow Profiler 踩坑记</div></div></a></div><div><a href="/2024/12/10/entropy/" title="再看交叉熵"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-10</div><div class="title">再看交叉熵</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ZM-J</div><div class="author-info__description">丧失年轻，勿失年华</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ZM-J"><i class="fab fa-github"></i><span>信春哥</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://www.zhihu.com/people/ZM_________J" target="_blank" title="Zhihu"><i class="fab fa-zhihu" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">春哥纯爷们，铁血真汉子。人民好兄弟，父亲好儿子。拳上能站人，臂上能走马！夜御十女枪不倒，菊花百战色仍红！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#keras-Sequential-%E4%B8%AD-model-build-%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">keras.Sequential 中 model.build 的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%97%B6-checkpoint-%E5%9B%9E%E8%B0%83%E4%B8%8D%E5%81%9C%E5%9C%B0%E6%8A%A5%E5%85%B3%E4%BA%8E-LSTMcell-%E7%9A%84-warning"><span class="toc-number">2.</span> <span class="toc-text">训练时 checkpoint 回调不停地报关于 LSTMcell 的 warning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93-model-fit-%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86%E4%BD%BF%E7%94%A8-generator-%E6%97%B6%E5%81%9C%E4%B8%8D%E4%B8%8B%E6%9D%A5"><span class="toc-number">3.</span> <span class="toc-text">当 model.fit 的训练集使用 generator 时停不下来</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93-model-fit-%E7%9A%84%E8%AE%AD%E7%BB%83%E9%9B%86%E4%BD%BF%E7%94%A8-generator-%E6%97%B6%E4%B8%8D%E8%83%BD%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">4.</span> <span class="toc-text">当 model.fit 的训练集使用 generator 时不能多线程取数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#cuDNN-%E4%B8%8D%E8%83%BD%E5%8A%A0%E8%BD%BD-dll"><span class="toc-number">5.</span> <span class="toc-text">cuDNN 不能加载 dll</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E-XLA"><span class="toc-number">6.</span> <span class="toc-text">关于 XLA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E6%94%B9%E6%A8%A1%E5%9E%8B%E9%87%8C%E9%9D%A2%E5%B1%82%E7%9A%84%E5%90%8D%E7%A7%B0"><span class="toc-number">7.</span> <span class="toc-text">更改模型里面层的名称</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/13/cryptoctf-2025-tough-cookie-2/" title="CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之二">CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之二</a><time datetime="2025-08-13T09:52:00.000Z" title="Created 2025-08-13 17:52:00">2025-08-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/08/04/cryptoctf-2025-tough-cookie-1/" title="CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之一">CryptoCTF 2025 tough cookie 分类 团队解题 writeup 之一</a><time datetime="2025-08-04T03:54:00.000Z" title="Created 2025-08-04 11:54:00">2025-08-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/cryptoctf-2025-getting-there-2/" title="CryptoCTF 2025 getting there 分类 团队解题 writeup 之二">CryptoCTF 2025 getting there 分类 团队解题 writeup 之二</a><time datetime="2025-07-25T07:29:00.000Z" title="Created 2025-07-25 15:29:00">2025-07-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/cryptoctf-2025-getting-there-1/" title="CryptoCTF 2025 getting there 分类 团队解题 writeup 之一">CryptoCTF 2025 getting there 分类 团队解题 writeup 之一</a><time datetime="2025-07-22T10:26:00.000Z" title="Created 2025-07-22 18:26:00">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/cryptoctf-2025-easy-peasy/" title="CryptoCTF 2025 easy-peasy 分类 团队解题 writeup">CryptoCTF 2025 easy-peasy 分类 团队解题 writeup</a><time datetime="2025-07-17T10:27:41.000Z" title="Created 2025-07-17 18:27:41">2025-07-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By ZM-J</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="chat-btn" type="button" title="Chat"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const initGitalk = () => {
    const gitalk = new Gitalk(Object.assign({
      clientID: 'Ov23lib8keprJGNom7Yt',
      clientSecret: 'ec292b94fcfc3c36860e77622a4a4b37639c983a',
      repo: 'ZM-J.github.io',
      owner: 'ZM-J',
      admin: ['ZM-J'],
      id: '5c49abc82b1b65a72c1ba0c0cde6f8f4',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async() => {
    if (typeof Gitalk === 'function') initGitalk()
    else {
      await getCSS('https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.css')
      await getScript('https://cdn.jsdelivr.net/npm/gitalk@1.8.0/dist/gitalk.min.js')
      initGitalk()
    }
  }
  
  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  if ('Gitalk' === 'Gitalk' || !false) {
    if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>